{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgathai/Various-note-books-_Practising/blob/master/%5BSolution_Notebook%5D_AfterWork_ML_Essentials_with_scikit_learn_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Solution Notebook] AfterWork: ML Essentials with scikit-learn Course"
      ],
      "metadata": {
        "id": "hwCK5RjRFswc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "RIVc7Y_IF_yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First import the libraries that we need.\n",
        "# ----\n",
        "import pandas as pd                   # library for performing data manipulation.\n",
        "import numpy as np                    # library for performing scientific computations.\n",
        "import matplotlib.pyplot as plt       # library for performing visualization."
      ],
      "metadata": {
        "id": "KNB450uQGjPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Classification"
      ],
      "metadata": {
        "id": "zFcYSGatVXEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal here is to categorize input data into predefined classes or labels."
      ],
      "metadata": {
        "id": "oasQcqu2Zwvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "nXTpnoys9zCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, we will use the random forest classifier and gradient boosting\n",
        "# classifier to predict discrete outcomes on a dataset.\n",
        "# ---\n",
        "# These models learn patterns in the training data and then use the information\n",
        "# learned to classify the testing data.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/3Sn7blU\n",
        "# ---\n",
        "# We first import our classification models.\n",
        "# ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "KLgi0JPaV0-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Importation"
      ],
      "metadata": {
        "id": "Ryv7RU03j02B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We import and preview our dataset.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/3Sn7blU\n",
        "# ---\n",
        "# This dataset contains observations of iris flowers including sepal and petal\n",
        "# length and width for each flower, as well as the species of the flower.\n",
        "# The labels are the species of the iris flower.\n",
        "# ---\n",
        "iris_df = pd.read_csv('https://bit.ly/3Sn7blU')\n",
        "\n",
        "# Check the first records.\n",
        "iris_df.head()"
      ],
      "metadata": {
        "id": "ryddWUoilIJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the last records.\n",
        "iris_df.tail()"
      ],
      "metadata": {
        "id": "7CC9iru9mUCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Exploration/ Cleaning/ Preparation/ Statistical Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "8JeY0yz2G8HK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will not perform extrensive exploration/ cleaning/ preparation/ statistical analysis steps here since the main focus of this part of the session is to make predictions on the dataset using a classification algorithm."
      ],
      "metadata": {
        "id": "fdVae--6g8CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We separate the features from the labels.\n",
        "# features\n",
        "iris_X = iris_df.drop('Species', axis=1)\n",
        "\n",
        "# labels\n",
        "iris_y = iris_df['Species']"
      ],
      "metadata": {
        "id": "I7G4IlimHCaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We scale the values of our features in order to give them equal importance.\n",
        "# Scaling allows the datapoints of our features to lie within the same upper and lower limits.\n",
        "# ---\n",
        "# We can perform feature scaling using StandardScaler.\n",
        "# ---\n",
        "# Perform normalization.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Implement the standard scaler\n",
        "standard_scaler = StandardScaler().fit(iris_X)\n",
        "iris_X = standard_scaler.transform(iris_X)"
      ],
      "metadata": {
        "id": "25t89-zd-vb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and a testing set.\n",
        "# To the train_test_split function we pass the feature matrix (iris_X), the target vector (iris_y), and test_size which\n",
        "# determines the percentage of data used for testing (20% in our case).\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_X, iris_y, test_size=0.2)"
      ],
      "metadata": {
        "id": "20mNi5X_-0sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 1: Random Forest Classifier"
      ],
      "metadata": {
        "id": "f1sqEyHxGoo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a random forest classifier that we'll use to perform classification.\n",
        "# ---\n",
        "# The random forest classifier is an ensemble learning method that builds multiple decision\n",
        "# trees and merges their predictions to obtain a more accurate and stable result.\n",
        "# ---\n",
        "random_forest_clf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "6ivKM5qAlHLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning/ model selection/ model parameter optimization is the process of searching for the best set of hyperparameters for a model.\n",
        "\n",
        "Hyperparameters are configuration settings for a machine learning model that are set before the training process begins while model parameters are those that are learned from the data during training.\n",
        "\n",
        "Hyperparameters influence the overall behaviour of the model and need to be specified by the user. Examples of hyperparameters include:\n",
        "- Learning rates.\n",
        "- Depth of a decision tree.\n",
        "- Number of layers in a neural network.\n",
        "\n"
      ],
      "metadata": {
        "id": "0hD3yLjFtHj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform hyperparameter tuning to optimize the model.\n",
        "# Hyperparameter tuning involves searching for the best set of hyperparameter\n",
        "# values that the model will explore during the tuning process.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# We define hyerparameter grids for the classifier.\n",
        "# `n_estimators` represents the number of trees in the random forest.\n",
        "# `max_depth` sets the maximum depth of each tree in the random forest.\n",
        "# `min_sample_split` is the minimum number of samples required to split an internal node.\n",
        "# `min_samples_leaf` sets the minimum number of samples required to be at a leaf node.\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# We perform a grid search.\n",
        "# GridSearchCV systematically evaluates all possible combinations of hyperparameter values\n",
        "# specified above. The model is trained and evaluated for each combination and the set of\n",
        "# hyperparameters that yields the best performance is chosen.\n",
        "grid_search_rfc = GridSearchCV(estimator=random_forest_clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# We pass our training data to GridSearch.\n",
        "grid_search_rfc.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "# We get the best model from GridSearch\n",
        "best_model_rfc = grid_search_rfc.best_estimator_"
      ],
      "metadata": {
        "id": "9NnKDrxy_EBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We make predictions using our trained classifier.\n",
        "y_pred_rfc = best_model_rfc.predict(iris_X_test)"
      ],
      "metadata": {
        "id": "dCS9S-2V_Gdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We the evaluate the performance of our classifier.\n",
        "# ---\n",
        "# Accuracy is a measure of the proportion of correctly classified samples out of the total number of samples,\n",
        "# the closer the accuracy score is to 1, the more better the model is at making predictions.\n",
        "# A confusion matrix is a table representing the performance of a model. It shows the true positive, true\n",
        "# negative, false positive, and false negative counts for each class. It is used to understand where a model\n",
        "# is making errors.\n",
        "# A classification report is a report displaying precision, recall, F1 score and support for each class. It is\n",
        "# useful for undertanding the performance of a model across different classes.\n",
        "# ---\n",
        "# Accuracy is a global measure while classification report and confusion matrix offer insights into class-specific performance.\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "accuracy_rfc = accuracy_score(iris_y_test, y_pred_rfc)\n",
        "conf_matrix_rfc = confusion_matrix(iris_y_test, y_pred_rfc)\n",
        "classification_rep_rfc = classification_report(iris_y_test, y_pred_rfc)\n",
        "\n",
        "print(f\"Accuracy: \")\n",
        "print(accuracy_rfc)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_rfc)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_rfc)"
      ],
      "metadata": {
        "id": "anBpTarJ_IlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "- **Accuracy:** An accuracy of 1.0 means that our model correctly classified all instances in the test dataset hence perfect performance.\n",
        "- **Confusion matrix:** The diagonal elements represent the number of correctly identified instances for each class. Off-diagonal elements are zeros, indicating no misclassifications\n",
        "- **Classification report:**\n",
        "  - **Precision:** All classes have precision score of 1.0 indicating no false positives.\n",
        "  - **Recall:** All classes have recall score of 1.0 indicating no false negatives.\n",
        "  - **F1-score:** All classes have F1-score of 1.0 indicating a balance between precision and recall.\n",
        "  - **Support:** This is the number of actual instances for each class"
      ],
      "metadata": {
        "id": "lT0cppfTtBqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation is a resampling technique used to assess the performance and the generalization capability of a model.\n",
        "\n",
        "It involves dividing the dataset into multiple subsets, training the model on some of these subsets, and evaluating it on the remaining subsets.\n",
        "\n",
        "Our goal is to obtain a more reliable estimate of a model's performance compared to a single train-test split and this is particularly important when dealing with limited datasets."
      ],
      "metadata": {
        "id": "i0mA9LdX-v70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform k-fold cross validation to obtain a more accurate and reliable estimate of the model's performance.\n",
        "# The dataset is divided into k subsets (folds) and the model is trained and evaluated k times, each time\n",
        "# using a different fold as the test set and the remaining folds as the training set.\n",
        "# ---\n",
        "# We use k=5.\n",
        "# ---\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores_rfc = cross_val_score(best_model_rfc, iris_X, iris_y, cv=5)\n",
        "print(\"\\nCross-Validation Scores: \", cv_scores_rfc)\n",
        "print(\"Mean Cross-Validation: \", np.mean(cv_scores_rfc))"
      ],
      "metadata": {
        "id": "b7EEG8Op_NaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "- The cross-validation scores indicate how well the model generalizes to different subsets of the data.\n",
        "- The model's accuracy ranges from 83.33% to 100% across different folds.\n",
        "- The mean cross-validation accuracy (95.33%) provides a more robust estimate of the model's overall performance, considering variability across different data subsets.\n",
        "\n",
        "The variation in scores across folds is due to differences in the composition of training and validation sets in each fold.\n",
        "\n",
        "A high mean cross-validation score (close to 1.0) suggests that the model performs well on average across different subsets of the data."
      ],
      "metadata": {
        "id": "RG6rOzuovVhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 2: Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "EmxKQHqRHLmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a gradient boosting classifier that we'll use to perform classification.\n",
        "# ---\n",
        "# The gradient boosting classifier is an ensemble learning method that builds decision\n",
        "# trees sequentially, each tree correcting the errors of the previous ones.\n",
        "# ---\n",
        "gradient_boosting_clf = GradientBoostingClassifier()"
      ],
      "metadata": {
        "id": "gRudDHZhHTlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning/ model selection/ model parameter optimization is the process of searching for the best set of hyperparameters for a model.\n",
        "\n",
        "Hyperparameters are configuration settings for a machine learning model that are set before the training process begins while model parameters are those that are learned from the data during training.\n",
        "\n",
        "Hyperparameters influence the overall behaviour of the model and need to be specified by the user. Examples of hyperparameters include:\n",
        "- Learning rates.\n",
        "- Depth of a decision tree.\n",
        "- Number of layers in a neural network.\n",
        "\n"
      ],
      "metadata": {
        "id": "RRrLQw6iv_L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform hyperparameter tuning to optimize the model.\n",
        "# Hyperparameter tuning involves searching for the best set of hyperparameter\n",
        "# values that the model will explore during the tuning process.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# We define hyperparameter grids for the classifier.\n",
        "# `n_estimators` represents the number of trees trained during the boosting process.\n",
        "# `learning_rate` scales the contribution of each tree when updating the model in the boosting process.\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "# We perform a grid search.\n",
        "# GridSearchCV systematically evaluates all possible combinations of hyperparameter values\n",
        "# specified above. The model is trained and evaluated for each combination and the set of\n",
        "# hyperparameters that yields the best performance is chosen.\n",
        "grid_search_gbc = GridSearchCV(estimator=gradient_boosting_clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# We pass our training data to GridSearch.\n",
        "grid_search_gbc.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "# We get the best model from GridSearch.\n",
        "best_model_gbc = grid_search_gbc.best_estimator_"
      ],
      "metadata": {
        "id": "Zddb8NTS_XFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise"
      ],
      "metadata": {
        "id": "AHreV7-52zSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `best_model_gbc` to make predictions on the training set.\n",
        "- Evaluate the model and interprate the results.\n",
        "- Perform k-fold cross-validation and evaluate the results."
      ],
      "metadata": {
        "id": "HZSKWhKEeL-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We then make predictions using our trained classifier.\n",
        "y_pred_gbc = best_model_gbc.predict(iris_X_test)"
      ],
      "metadata": {
        "id": "ehx3TQ2l_aBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We evaluate the performance of our classifier.\n",
        "# ---\n",
        "# Accuracy is a measure of the proportion of correctly classified samples out of the total number of samples,\n",
        "# the closer the accuracy score is to 1, the more better the model is at making predictions.\n",
        "# A confusion matrix is a table representing the performance of a model. It shows the true positive, true\n",
        "# negative, false positive, and false negative counts for each class. It is used to understand where a model\n",
        "# is making errors.\n",
        "# A classification report is a report displaying precision, recall, F1 score and support for each class. It is\n",
        "# useful for undertanding the performance of a model across different classes.\n",
        "# ---\n",
        "# Accuracy is a global measure while classification report and confusion matrix offer insights into class-specific performance.\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Calculate accuracy, classification report and confusion matrix\n",
        "accuracy_gbc = accuracy_score(iris_y_test, y_pred_gbc)\n",
        "conf_matrix_gbc = confusion_matrix(iris_y_test, y_pred_gbc)\n",
        "classification_rep_gbc = classification_report(iris_y_test, y_pred_gbc)\n",
        "\n",
        "# Display the metrics calculated above and interprate them\n",
        "print(f\"Accuracy: \")\n",
        "print(accuracy_gbc)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_gbc)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_gbc)"
      ],
      "metadata": {
        "id": "c3eZLy2t_dgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform k-fold cross validation to obtain a more accurate and reliable estimate of the model's performance.\n",
        "# The dataset is divided into k subsets (folds) and the model is trained and evaluated k times, each time\n",
        "# using a different fold as the test set and the remaining folds as the training set.\n",
        "# ---\n",
        "# We use k=5.\n",
        "# ---\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Calculate the cross-validation scores.\n",
        "cv_scores_gbc = cross_val_score(best_model_gbc, iris_X, iris_y, cv=5)\n",
        "# Print out the scores and find the average score\n",
        "print(\"\\nCross-Validation Scores: \", cv_scores_gbc)\n",
        "print(\"Mean Cross-Validation: \", np.mean(cv_scores_gbc))"
      ],
      "metadata": {
        "id": "-A8Kn9_K_g1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge 1"
      ],
      "metadata": {
        "id": "Rp9Bp2VHpKZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification challenge 1.\n",
        "# ---\n",
        "# A cancer researcher has given data on breast tumors features such as size and density.\n",
        "# Implement a  support vector machine classification model to predict whether the tumors are benign or malignant.\n",
        "# Evaluate the performance of your classifier.\n",
        "# Hint: Check for missing values in the data and handle them using an imputation technique.\n",
        "# ---\n",
        "# Dataset URL = https://bit.ly/data_breast_cancer\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW."
      ],
      "metadata": {
        "id": "3ux1j3POtn8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution for challenge 1"
      ],
      "metadata": {
        "id": "dSV5qgRQ5jZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-code for data loading and preprocessing has been provided below."
      ],
      "metadata": {
        "id": "7DkhpjDe6CVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Breast Cancer dataset.\n",
        "cancer_df = pd.read_csv('https://bit.ly/data_breast_cancer')\n",
        "\n",
        "# Extract features and labels.\n",
        "cancer_X = cancer_df.drop('diagnosis', axis=1)\n",
        "cancer_y = cancer_df['diagnosis']"
      ],
      "metadata": {
        "id": "mqT_Vs-c5nn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values in data.\n",
        "nan_values = cancer_X.isnull().any()\n",
        "if nan_values.any():\n",
        "    print(\"There are missing values in the data.\")\n",
        "    print(nan_values)"
      ],
      "metadata": {
        "id": "M3vP1UM35_79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute missing values with the most frequent value.\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "cancer_X_imputed = imputer.fit_transform(cancer_X)"
      ],
      "metadata": {
        "id": "Q02xLQqs585Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features using StandardScaler.\n",
        "scaler = StandardScaler()\n",
        "cancer_X_scaled = scaler.fit_transform(cancer_X_imputed)"
      ],
      "metadata": {
        "id": "0xsmMmcR6msC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, write your code for the rest of your solution."
      ],
      "metadata": {
        "id": "gXK-Zu4q6VS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Split the dataset into a training and testing set using train_test_split.\n",
        "cancer_X_train, cancer_X_test, cancer_y_train, cancer_y_test = train_test_split(cancer_X_scaled, cancer_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a support vector machine classifier.\n",
        "svm_clf = SVC()\n",
        "\n",
        "# Train your classifier.\n",
        "svm_clf.fit(cancer_X_train, cancer_y_train)\n",
        "\n",
        "# Make predictions on the testing set using your classifier.\n",
        "y_pred_svm = svm_clf.predict(cancer_X_test)\n",
        "\n",
        "# Evaluate the performance of your classifier.\n",
        "accuracy_svm = accuracy_score(cancer_y_test, y_pred_svm)\n",
        "conf_matrix_svm = confusion_matrix(cancer_y_test, y_pred_svm)\n",
        "classification_rep_svm = classification_report(cancer_y_test, y_pred_svm)\n",
        "\n",
        "print(\"Accuracy:\")\n",
        "print(accuracy_svm)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_svm)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_svm)\n",
        "\n",
        "# Perform 5-fold cross validation and interprate the result.\n",
        "cv_scores_svm = cross_val_score(svm_clf, cancer_X_imputed, cancer_y, cv=5)\n",
        "print(\"\\nCross-Validation Scores: \", cv_scores_svm)\n",
        "print(\"Mean Cross-Validation: \", np.mean(cv_scores_svm))"
      ],
      "metadata": {
        "id": "cIaUO6Zz67ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge 2"
      ],
      "metadata": {
        "id": "cuiCNTnW7008"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification challenge 2.\n",
        "# ---\n",
        "# This challenge is an extension of challange 1. It requires you to perform hyperparameter tuning.\n",
        "# Using the same cancer dataset, implement a logistic regression classification model to predict\n",
        "# whether tumors are benign or malignant.\n",
        "# Perform hyperparameter tuning on your model to optimize its performance.\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW."
      ],
      "metadata": {
        "id": "wFO3ohjCE6td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution for challenge 2"
      ],
      "metadata": {
        "id": "tOQu3ovl77xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make use of the split dataset from chalenge 1\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Initialize a logistic regression classifier.\n",
        "logistic_reg = LogisticRegression()\n",
        "\n",
        "# Train your classifier.\n",
        "logistic_reg.fit(cancer_X_train, cancer_y_train)\n",
        "\n",
        "# Make predictions on the testing set using your classifier.\n",
        "logistic_y_pred = logistic_reg.predict(cancer_X_test)\n",
        "\n",
        "# Evaluate the performance of your classifier.\n",
        "logistic_accuracy = accuracy_score(cancer_y_test, logistic_y_pred)\n",
        "logistic_conf_matrix = confusion_matrix(cancer_y_test, logistic_y_pred)\n",
        "logistic_class_report = classification_report(cancer_y_test, logistic_y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", logistic_accuracy)\n",
        "print(\"Confusion Matrix:\\n\", logistic_conf_matrix)\n",
        "print(\"Classification Report:\\n\", logistic_class_report)"
      ],
      "metadata": {
        "id": "_YXjLks5F6nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform hyperparameter tuning on your logistic regression classifier.\n",
        "# Define hyperparameter grid for optimization.\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning.\n",
        "grid_search = GridSearchCV(logistic_reg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(cancer_X_train, cancer_y_train)\n",
        "\n",
        "# We get the best model from GridSearch.\n",
        "logistic_best_model = grid_search_rfc.best_estimator_\n",
        "\n",
        "# Train the best model.\n",
        "logistic_best_model.fit(cancer_X_train, cancer_y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "logistic_y_pred = logistic_best_model.predict(cancer_X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "logistic_accuracy = accuracy_score(cancer_y_test, logistic_y_pred)\n",
        "logistic_conf_matrix = confusion_matrix(cancer_y_test, logistic_y_pred)\n",
        "logistic_class_report = classification_report(cancer_y_test, logistic_y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", logistic_accuracy)\n",
        "print(\"Confusion Matrix:\\n\", logistic_conf_matrix)\n",
        "print(\"Classification Report:\\n\", logistic_class_report)\n",
        "\n",
        "# Perform 5-fold cross validation and interprate the result.\n",
        "cv_scores_logistic = cross_val_score(logistic_best_model, cancer_X_scaled, cancer_y, cv=5)\n",
        "print(\"\\nCross-Validation Scores: \", cv_scores_logistic)\n",
        "print(\"Mean Cross-Validation: \", np.mean(cv_scores_logistic))"
      ],
      "metadata": {
        "id": "6aeSwOpzW9HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Regression"
      ],
      "metadata": {
        "id": "xN--ATbftxYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal here is to predict a continuous value."
      ],
      "metadata": {
        "id": "sQpzVbRLaET5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "fNEVf2Zx_5i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, we will use the linear regressor and ridge\n",
        "# regressor to predict continuous outcomes on a dataset.\n",
        "# ---\n",
        "# These models learn patterns in the training data and then use\n",
        "# the information learned to predict a value.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/data_boston_housing\n",
        "# ---\n",
        "# We first import our regression models.\n",
        "# ---\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge"
      ],
      "metadata": {
        "id": "tYEhC-YQty0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Importation"
      ],
      "metadata": {
        "id": "WIUuHmoq2gXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We import and preview our dataset.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/data_boston_housing\n",
        "# ---\n",
        "# This dataset contains observations of the characteristics of the area in which a house is located and the features of the house.\n",
        "# Our goal is to predict median housing price given the characteristics of its location and the house's features.\n",
        "# ---\n",
        "housing_df = pd.read_csv('https://bit.ly/data_boston_housing')\n",
        "\n",
        "# Check the first records.\n",
        "housing_df.head()"
      ],
      "metadata": {
        "id": "tIx4iqFs2r_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the last records.\n",
        "housing_df.tail()"
      ],
      "metadata": {
        "id": "Fghs2m8RAG8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Exploration/ Cleaning/ Preparation/ Statistical Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "XPkhY18uHgWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will not perform extrensive exploration/ cleaning/ preparation/ statistical analysis steps here since the main focus of this part of the session is to make predictions on the dataset using a regression algorithm."
      ],
      "metadata": {
        "id": "zcSSWgpyg1Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values.\n",
        "print(\"\\nMissing values in the dataset:\")\n",
        "print(housing_df.isnull().sum())"
      ],
      "metadata": {
        "id": "4NmcmC7NHmuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values using mean imputation.\n",
        "# Imputation is the process of replacing missing or incopmlete data with substituted values.\n",
        "# Here, we use SimpleImputer to perform mean imputation which replaces missing values\n",
        "# with the mean of the observed values in the same column.\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(housing_df), columns=housing_df.columns)"
      ],
      "metadata": {
        "id": "0DiFgNogAY8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the features from the labels.\n",
        "# features\n",
        "housing_X = df_imputed.drop('MEDV', axis=1)\n",
        "\n",
        "# labels\n",
        "housing_y = df_imputed['MEDV']"
      ],
      "metadata": {
        "id": "HMfIt-tFAcsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and a testing set.\n",
        "# To the train_test_split function we pass the feature matrix (housing_X), the target vector (housing_y), and test_size which\n",
        "# determines the percentage of data used for testing (20% in our case).\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing_X_train, housing_X_test, housing_y_train, housing_y_test = train_test_split(housing_X, housing_y, test_size=0.2)"
      ],
      "metadata": {
        "id": "GWthuhtwAe1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 1: Linear Regression"
      ],
      "metadata": {
        "id": "ZVphbz7wAicf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a linear regressor that we'll use to make predictions.\n",
        "# ---\n",
        "# The linear regressor is an method that finds the best-fit linear relationship that\n",
        "# minimizes the difference between predicted values and actual values of the target variable.\n",
        "# ---\n",
        "linear_regressor = LinearRegression()"
      ],
      "metadata": {
        "id": "7J5gv-IBAlma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We pass our training data to the model.\n",
        "linear_regressor.fit(housing_X_train, housing_y_train)"
      ],
      "metadata": {
        "id": "DmsuecpSAnl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We make predictions using our trained regressor.\n",
        "y_pred_linear = linear_regressor.predict(housing_X_test)"
      ],
      "metadata": {
        "id": "vXWRh6nRApmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We evaluate the performance of our regressor.\n",
        "# ---\n",
        "# Mean Square Error (MSE) is the average squared difference between the predicted and actual values.\n",
        "# A lower MSE indicates better model performance.\n",
        "# R2 Score/ Coefficient of Determination measures the proportion on variance in the dependent\n",
        "# variable that is explained by the independent variable in the regression model. It ranges from 0 to 1\n",
        "# with 0 indicating that the model explains none of the variance and 1 indicating a perfect fit.\n",
        "# ---\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# Evaluate the model on imputed data.\n",
        "mse_linear = mean_squared_error(housing_y_test, y_pred_linear)\n",
        "r2_linear = r2_score(housing_y_test, y_pred_linear)\n",
        "\n",
        "# Display results.\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(\"Mean Squared Error (MSE): \")\n",
        "print(mse_linear)\n",
        "print(\"R-squared (R2): \")\n",
        "print(r2_linear)"
      ],
      "metadata": {
        "id": "Gxgg1mGeAr0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "- The MSE of 30.85 suggests that, on average, the squared difference between predicted and actual values is 30.85. Smaller MSE values are desirable.\n",
        "- The R-squared value of 0.68 indicates that the model captures about 68.18% of the variability in the target variable. While this is a reasonable fit, it also suggests that there is room for improvement."
      ],
      "metadata": {
        "id": "ZyXDA8XWxSW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation is a resampling technique used to assess the performance and the generalization capability of a model.\n",
        "\n",
        "It involves dividing the dataset into multiple subsets, training the model on some of these subsets, and evaluating it on the remaining subsets.\n",
        "\n",
        "Our goal is to obtain a more reliable estimate of a model's performance compared to a single train-test split and this is particularly important when dealing with limited datasets."
      ],
      "metadata": {
        "id": "_rjuFqa2BTbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform k-fold cross validation to obtain a more accurate and reliable estimate of the model's performance.\n",
        "# The dataset is divided into k subsets (folds) and the model is trained and evaluated k times, each time\n",
        "# using a different fold as the test set and the remaining folds as the training set.\n",
        "# ---\n",
        "# We use k=5.\n",
        "# ---\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores_linear = cross_val_score(linear_regressor, housing_X, housing_y, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_rmse_scores_linear = np.sqrt(-cv_scores_linear)\n",
        "print(\"\\nCross-Validation RMSE Scores:\")\n",
        "print(cv_rmse_scores_linear)\n",
        "print(\"Mean RMSE Score:\", np.mean(cv_rmse_scores_linear))"
      ],
      "metadata": {
        "id": "gkBm4QxRAuKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "- RMSE is a measure of the average magnitude of errors between predicted and actual values in a regression model.\n",
        "- The model's RMSE varies across different folds, ranging from 3.43 to 9.01.\n",
        "- The mean RMSE (5.88) provides an overall measure of the model's predictive performance, considering variability across different data subsets.\n",
        "- A lower RMSE indicates better model performance, as it represents smaller errors in predictions."
      ],
      "metadata": {
        "id": "Fg-zGF7UxikQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 2: Ridge Regression"
      ],
      "metadata": {
        "id": "Swxf8HA6H13N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a ridge regressor that we'll use to perform classification\n",
        "# ---\n",
        "# The ridge regressor is a method that finds the best-fit linear relationship that\n",
        "# minimizes the difference between predicted values and actual values of the target variable.\n",
        "# It prevents overfitting and handles multicollinearity (high correlation between predictors)\n",
        "# by adding a regularization term to the cost function.\n",
        "# ---\n",
        "ridge_regressor = Ridge()"
      ],
      "metadata": {
        "id": "vZ5o_s5wq1Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning/ model selection/ model parameter optimization is the process of searching for the best set of hyperparameters for a model.\n",
        "\n",
        "Hyperparameters are configuration settings for a machine learning model that are set before the training process begins while model parameters are those that are learned from the data during training.\n",
        "\n",
        "Hyperparameters influence the overall behaviour of the model and need to be specified by the user. Examples of hyperparameters include:\n",
        "- Learning rates.\n",
        "- Depth of a decision tree.\n",
        "- Number of layers in a neural network.\n",
        "\n"
      ],
      "metadata": {
        "id": "TdhwsvUIB2O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform hyperparameter tuning to optimize the model.\n",
        "# Hyperparameter tuning involves searching for the best set of hyperparameter\n",
        "# values that the model will explore during the tuning process.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# We define hyperparameter grids for the classifier.\n",
        "# `alpha` controls the strength of the regularization term in the model. Smaller\n",
        "# values allow for less regularization while larger values impose stronger regularization.\n",
        "# Our model uses ridge regularization(L2) to prevent overfitting.\n",
        "param_grid = {'alpha': [0.1, 1, 10]}\n",
        "\n",
        "# We perform a grid search.\n",
        "grid_search_ridge = GridSearchCV(estimator=ridge_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# We pass our training data to GridSearch.\n",
        "grid_search_ridge.fit(housing_X_train, housing_y_train)\n",
        "\n",
        "# We get the best model from GridSearch.\n",
        "best_model_ridge = grid_search_ridge.best_estimator_"
      ],
      "metadata": {
        "id": "7v36KD5iA362"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise"
      ],
      "metadata": {
        "id": "Iy00oJHEhxGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `best_model_ridge` to make predictions on the training set.\n",
        "- Evaluate the model and interprate the results.\n",
        "- Perform k-fold cross-validation and evaluate the results."
      ],
      "metadata": {
        "id": "p9TKRMTBh6Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We then make predictions using our trained regressor.\n",
        "y_pred_ridge = best_model_ridge.predict(housing_X_test)"
      ],
      "metadata": {
        "id": "GXjcykd1A6QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We evaluate the performance of our regressor.\n",
        "# ---\n",
        "# Mean Square Error (MSE) is the average squared difference between the predicted and actual values.\n",
        "# A lower MSE indicates better model performance.\n",
        "# R2 Score/ Coefficient of Determination measures the proportion on variance in the dependent\n",
        "# variable that is explained by the independent variable in the regression model. It ranges from 0 to 1\n",
        "# with 0 indicating that the model explains none of the variance and 1 indicating a perfect fit.\n",
        "# ---\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Calculate MSE and R2 score.\n",
        "mse_ridge = mean_squared_error(housing_y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(housing_y_test, y_pred_ridge)\n",
        "\n",
        "# Display results.\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(\"Mean Squared Error (MSE): \")\n",
        "print(mse_ridge)\n",
        "print(\"R-squared (R2): \")\n",
        "print(r2_ridge)"
      ],
      "metadata": {
        "id": "a0UeXLdVA8F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We perform k-fold cross validation to obtain a more accurate and reliable estimate of the model's performance.\n",
        "# The dataset is divided into k subsets (folds) and the model is trained and evaluated k times, each time\n",
        "# using a different fold as the test set and the remaining folds as the training set.\n",
        "# ---\n",
        "# We use k=5.\n",
        "# ---\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Calculate the cross-validation scores.\n",
        "cv_scores_ridge = cross_val_score(ridge_regressor, housing_X, housing_y, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_rmse_scores_ridge = np.sqrt(-cv_scores_ridge)\n",
        "\n",
        "# Print out the scores and find the average score.\n",
        "print(\"\\nCross-Validation RMSE Scores:\")\n",
        "print(cv_rmse_scores_ridge)\n",
        "print(\"Mean RMSE Score:\", np.mean(cv_rmse_scores_ridge))"
      ],
      "metadata": {
        "id": "O5rAJFQNA-Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge 1"
      ],
      "metadata": {
        "id": "IPVsZtaAIFsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression challenge 1.\n",
        "# ---\n",
        "# A 1990 cencus gave data on housing prices and some summary statistics about these houses.\n",
        "# Implement a lasso regression model to predict housing prices.\n",
        "# Evaluate the performance of your regressor.\n",
        "# ---\n",
        "# Dataset URL = https://bit.ly/3Sqd1nU\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW."
      ],
      "metadata": {
        "id": "4l3drMmBBDZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution for challenge 1"
      ],
      "metadata": {
        "id": "2N1FY-owApi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-code for data loading and preprocessing has been provided below."
      ],
      "metadata": {
        "id": "eU3c3CCwA2LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset.\n",
        "california_df = pd.read_csv('https://bit.ly/3Sqd1nU')\n",
        "\n",
        "# Extract features and labels\n",
        "california_X = california_df.drop('median_house_value', axis=1)\n",
        "california_y = california_df['median_house_value']"
      ],
      "metadata": {
        "id": "O-6SvYDDA5DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variable `ocean_proximity`\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "california_X['ocean_proximity'] = label_encoder.fit_transform(california_X['ocean_proximity'])\n",
        "\n",
        "california_X.head()"
      ],
      "metadata": {
        "id": "S-dWcaRtBNj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values in data\n",
        "nan_values = california_X.isnull().any()\n",
        "if nan_values.any():\n",
        "    print(\"There are missing values in the data.\")\n",
        "    print(nan_values)"
      ],
      "metadata": {
        "id": "YW_4OAyGBZJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute missing values with the most frequent value\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "california_X_imputed = imputer.fit_transform(california_X)"
      ],
      "metadata": {
        "id": "TPJL46tjBcYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, write your code for the rest of your solution."
      ],
      "metadata": {
        "id": "ECaUU5_pBlkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Split the dataset into a training and testing set using train_test_split.\n",
        "california_X_train, california_X_test, california_y_train, california_y_test = train_test_split(california_X_imputed, california_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a lasso regressor.\n",
        "lasso_reg = Lasso()\n",
        "\n",
        "# Train your regressor.\n",
        "lasso_reg.fit(california_X_train, california_y_train)\n",
        "\n",
        "# Make predictions on the testing set using your regressor.\n",
        "y_pred_lasso = lasso_reg.predict(california_X_test)\n",
        "\n",
        "# Evaluate the performance of your regressor.\n",
        "mse_lasso = mean_squared_error(california_y_test, y_pred_lasso)\n",
        "r2_lasso = r2_score(california_y_test, y_pred_lasso)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_lasso}\")\n",
        "print(f\"R-squared (R2): {r2_lasso}\")\n",
        "\n",
        "# Perform 5-fold cross validation and interprate the result.\n",
        "cv_scores_lasso = cross_val_score(lasso_reg, housing_X, housing_y, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_rmse_scores_lasso = np.sqrt(-cv_scores_lasso)\n",
        "\n",
        "# Print out the scores and find the average score.\n",
        "print(\"\\nCross-Validation RMSE Scores:\")\n",
        "print(cv_rmse_scores_lasso)\n",
        "print(\"Mean RMSE Score:\", np.mean(cv_rmse_scores_lasso))"
      ],
      "metadata": {
        "id": "OaxVaF7GBmvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge 2"
      ],
      "metadata": {
        "id": "8wFNPHHQG0M6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression challenge 2.\n",
        "# ---\n",
        "# This challenge is an extension of challange 1. It requires you to perform hyperparameter tuning.\n",
        "# Using the same California housing dataset, implement a random forest regression model to predict\n",
        "# median housing prices given features of a house.\n",
        "# Evaluate the performance of your regressor.\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW."
      ],
      "metadata": {
        "id": "yKFcRiDjG7Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution for challenge 2"
      ],
      "metadata": {
        "id": "UQDbK84JG2fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make use of the split dataset from chalenge 1\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize a random forest regressor.\n",
        "rfr_regressor = RandomForestRegressor()\n",
        "\n",
        "# Train your regressor.\n",
        "rfr_regressor.fit(california_X_train, california_y_train)\n",
        "\n",
        "# Make predictions on the testing set using your regressor.\n",
        "y_pred_rfr = rfr_regressor.predict(california_X_test)\n",
        "\n",
        "# Evaluate the performance of your regressor.\n",
        "mse_rfr = mean_squared_error(california_y_test, y_pred_rfr)\n",
        "r2_rfr = r2_score(california_y_test, y_pred_rfr)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_rfr}\")\n",
        "print(f\"R-squared (R2): {r2_rfr}\")"
      ],
      "metadata": {
        "id": "LjCucUCAIKH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform hyperparameter tuning on your random forest regressor.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Get the best model and evaluate its performance.\n",
        "best_rfr_regressor = grid_search.best_estimator_\n",
        "best_rfr_regressor.fit(california_X_train, california_y_train)\n",
        "y_pred_best_rfr = best_rfr_regressor.predict(california_X_test)\n",
        "\n",
        "mse_best_rfr = mean_squared_error(california_y_test, y_pred_best_rfr)\n",
        "r2_best_rfr = r2_score(california_y_test, y_pred_best_rfr)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_best_rfr}\")\n",
        "print(f\"R-squared (R2): {r2_best_rfr}\")"
      ],
      "metadata": {
        "id": "j-jfoQ_cVzO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Clustering"
      ],
      "metadata": {
        "id": "ZuudYx0wBIYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal here is to group similar data points together based on certain characteristics or features."
      ],
      "metadata": {
        "id": "2SGpjiuxaRUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "Ex8lzC52BMvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, we will use the k-means clustering and hierarchical\n",
        "# clustering to group data.\n",
        "# ---\n",
        "# These models learn patterns in the data and then uses the information\n",
        "# learned to group the data into clusters.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/3OdeHP6\n",
        "# ---\n",
        "# We first import our clustering models.\n",
        "# ---\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "metadata": {
        "id": "9yRfOnrgBJmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Importation"
      ],
      "metadata": {
        "id": "9ReVy4sZBRAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We import and preview our dataset.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/3OdeHP6\n",
        "# ---\n",
        "# This dataset contains observations of wine features with the labels removed\n",
        "# for clustering task.\n",
        "# ---\n",
        "wine_df = pd.read_csv('https://bit.ly/3OdeHP6')\n",
        "\n",
        "# Checking the first records.\n",
        "wine_df.head()"
      ],
      "metadata": {
        "id": "4bkrWj7TBRbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the last records.\n",
        "wine_df.tail()"
      ],
      "metadata": {
        "id": "AvN379Z9BVTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Exploration/ Cleaning/ Preparation/ Statistical Analysis\n",
        "\n",
        "We will not perform extrensive exploration/ cleaning/ preparation/ statistical analysis steps here since the main focus of this part of the session is to perform clustering analysis on the dataset."
      ],
      "metadata": {
        "id": "ygiifqL6BaHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We scale the values of our features in order to give them equal importance.\n",
        "# Scaling allows the datapoints of our features to lie within the same upper and lower limits.\n",
        "# ---\n",
        "# We can perform feature scaling using MinMaxScaler.\n",
        "# ---\n",
        "# Standardize features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "wine_df_scaled = scaler.fit_transform(wine_df)"
      ],
      "metadata": {
        "id": "wBUzKsG4BZll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the standardized dataset\n",
        "plt.scatter(wine_df_scaled[:, 0], wine_df_scaled[:, 1], edgecolor='k')\n",
        "plt.title('Standardized Wine Dataset')\n",
        "plt.xlabel('Feature 1 (Standardized)')\n",
        "plt.ylabel('Feature 2 (Standardized)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cw5KBgjzBdnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 1: K-Means Clustering"
      ],
      "metadata": {
        "id": "z4BI7bC9Bl_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code utilizes the Elbow Method to determine the optimal number of clusters (K) for K-Means\n",
        "# It calculates the inertia (within-cluster sum of squares) for different values of K and\n",
        "# plots the results.\n",
        "\n",
        "# Choose the number of clusters using the Elbow Method.\n",
        "inertia = []\n",
        "# The loop below iterates from k=1 to k=10, creating and fitting a model to the dataset for\n",
        "# each value of k.\n",
        "# It then calculates `kmeans.inertia` which is the the sum of squared distances of samples\n",
        "# to their closest cluster center and adds this value to the list inertia.\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(wine_df_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Method.\n",
        "plt.plot(range(1, 11), inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FB31ZUe4BmjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the optimal number of clusters and train the KMeans model.\n",
        "# From the plot above, we look for the \"elbow\" point where the inertia starts\n",
        "# decreasing at a slower rate. This point is considered a good estimate for\n",
        "# the optimal number of clusters.\n",
        "# In our case, our \"elbow\" point is k=3 and we assign this value to the variable\n",
        "# `optimal_k`.\n",
        "optimal_k = 3\n",
        "kmeans_model = KMeans(n_clusters=optimal_k)\n",
        "y_pred_kmeans = kmeans_model.fit_predict(wine_df_scaled)"
      ],
      "metadata": {
        "id": "mvJpGQDzBruX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the clustering result.\n",
        "# We create a scatter plot using Matplotlib.\n",
        "# `wine_df_scaled[:, 0]` extracts values from all rows of the first column\n",
        "# `wine_df_scaled[:, 1]` extracts values from all rows of the second column\n",
        "# The `c` parameter specifies the colour of each point in the scatter plot. In our case,\n",
        "# the colour is determined by the cluster labels assigned to datapoints by our model.\n",
        "plt.scatter(wine_df_scaled[:, 0], wine_df_scaled[:, 1], c=y_pred_kmeans)\n",
        "plt.title('Clustering Result (Wine Dataset)')\n",
        "plt.xlabel('Feature 1 (Standardized)')\n",
        "plt.ylabel('Feature 2 (Standardized)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "beKwRZyVBtzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Silhouette Score is calculated to assess the quality of the clustering result.\n",
        "# It is used to measure how well-separated clusters are in our clustering result.\n",
        "# It quantifies how similar an object is to its own cluster (cohesion) compared to\n",
        "# other clusters (separation).\n",
        "# A near +1 score indicates an object is well matched to its own cluster and poorly matched\n",
        "# to neighbouring clusters, hence good clustering.\n",
        "# A near 0 score indicates an object is on or very close to the decision boundary between two\n",
        "# neighbouring clusters.\n",
        "# A near -1 score indicates that an object might be assigned to the wrong cluster.\n",
        "# To calculate the average silhouette score for the entire dataset we use silhouetter_score()\n",
        "# function and to this function we pass our dataset (wine_df_scaled) and the array containing\n",
        "# the cluster labels assigned by our model to each data point (y_pred_kmeans).\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Evaluate the clustering using silhouette score\n",
        "silhouette_avg = silhouette_score(wine_df_scaled, y_pred_kmeans)\n",
        "print('Silhouette Score: ')\n",
        "print(silhouette_avg)"
      ],
      "metadata": {
        "id": "E-KjjqitBwJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "- The silhouette score ranges from -1 to 1, where a higher score indicates better separation between clusters.\n",
        "- A score around 0.30 suggests that the clusters have a moderate level of separation. It indicates that data points within clusters are somewhat well-separated, but there is still room for improvement.\n",
        "- Values close to 1.0 would indicate very well-defined clusters, while values close to -1.0 would suggest overlapping clusters."
      ],
      "metadata": {
        "id": "ibFZ6xb2y2Jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 2: Hierarchical Clustering"
      ],
      "metadata": {
        "id": "YiHui0NRBzax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A dendrogram to help visually determine the optimal number of clusters for hierarchical clustering.\n",
        "# A dendrogram is a tree-like diagram that illustrates the hierarchical relationship between data points.\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Create a dendrogram to determine the optimal number of clusters\n",
        "linked = linkage(wine_df_scaled, 'ward')  # 'ward' method minimizes the variance within each cluster\n",
        "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
        "plt.title('Dendrogram for Hierarchical Clustering')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Cluster Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cTN7ZQCfBzyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise"
      ],
      "metadata": {
        "id": "0Ga9yJzDmn48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Select optimal k, initialize the model and fit the model.\n",
        "- Evaluate the model and interprate the results."
      ],
      "metadata": {
        "id": "-5V2hzZ3m8Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AgglomerativeClustering algorithm is used for hierarchical clustering with a specified number of clusters\n",
        "# Choose the optimal number of clusters and perform hierarchical clustering\n",
        "# By observing the dendrogram, we can identify branches where clusters are formed and determine a suitable\n",
        "# cut point to define the number of clusters.\n",
        "# The height at which we cut the dendrogram corresponds to the desired number of clusters. In our case, k=3.\n",
        "\n",
        "optimal_k = 3\n",
        "hierarchical_model = AgglomerativeClustering(n_clusters=optimal_k)\n",
        "y_pred_hierarchical = hierarchical_model.fit_predict(wine_df_scaled)"
      ],
      "metadata": {
        "id": "NLZJPswrB5qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the clustering result.\n",
        "# We create a scatter plot using Matplotlib.\n",
        "# `wine_df_scaled[:, 0]` extracts values from all rows of the first column\n",
        "# `wine_df_scaled[:, 1]` extracts values from all rows of the second column\n",
        "# The `c` parameter specifies the colour of each point in the scatter plot. In our case,\n",
        "# the colour is determined by the cluster labels assigned to datapoints by our model.\n",
        "plt.scatter(wine_df_scaled[:, 0], wine_df_scaled[:, 1], c=y_pred_hierarchical)\n",
        "plt.title('Clustering Result (Wine Dataset)')\n",
        "plt.xlabel('Feature 1 (Standardized)')\n",
        "plt.ylabel('Feature 2 (Standardized)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZYKwWW10B7oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Silhouette Score is calculated to assess the quality of the clustering result.\n",
        "# It is used to measure how well-separated clusters are in our clustering result.\n",
        "# It quantifies how similar an object is to its own cluster (cohesion) compared to\n",
        "# other clusters (separation).\n",
        "# A near +1 score indicates an object is well matched to its own cluster and poorly matched\n",
        "# to neighbouring clusters, hence good clustering.\n",
        "# A near 0 score indicates an object is on or very close to the decision boundary between two\n",
        "# neighbouring clusters.\n",
        "# A near -1 score indicates that an object might be assigned to the wrong cluster.\n",
        "# To calculate the average silhouette score for the entire dataset we use silhouetter_score()\n",
        "# function and to this function we pass our dataset (wine_df_scaled) and the array containing\n",
        "# the cluster labels assigned by our model to each data point (y_pred_kmeans).\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Evaluate the clustering using silhouette score\n",
        "silhouette_avg = silhouette_score(wine_df_scaled, y_pred_hierarchical)\n",
        "print(f'Silhouette Score: {silhouette_avg:.2f}')"
      ],
      "metadata": {
        "id": "3GA0H3tJNrc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge 1"
      ],
      "metadata": {
        "id": "CPqSioLrB-ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering challenge 1.\n",
        "# ---\n",
        "# A biology researcher provide data on observations of iris flowers including\n",
        "# sepal and petal length and width for each flower, as well as the species of the flower\n",
        "# The labels are the species of the flower.\n",
        "# Perfom k-means clustering analysis on the dataset.\n",
        "# ---\n",
        "# Dataset URL = https://bit.ly/data_iris_dataset\n",
        "# Hint: We will drop the label column to perform clustering\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW."
      ],
      "metadata": {
        "id": "agyVC4lxB_JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution for challenge 1"
      ],
      "metadata": {
        "id": "fAeABDAaCKAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-code for data loading and preprocessing has been provided below."
      ],
      "metadata": {
        "id": "tA3rRF-6CQOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# import the dataset using pandas.\n",
        "iris_df = pd.read_csv('https://bit.ly/data_iris_dataset')\n",
        "\n",
        "# drop label column.\n",
        "X = iris_df.drop('Species', axis=1)\n",
        "\n",
        "# standardize features.\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "kC6HzrcUCMsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, write your code for the rest of your solution."
      ],
      "metadata": {
        "id": "s1bboBDLDxCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Elbow Method to determine the optimal number of clusters.\n",
        "# Plot the Elbow Method to find the \"elbow\" point.\n",
        "inertia = []\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Method\n",
        "plt.plot(range(1, 11), inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GhJy-tVjCZ_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Apply KMeans clustering.\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Visualize the clustering result.\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters)\n",
        "plt.title('Clustering Result (Iris Dataset)')\n",
        "plt.xlabel('Feature 1 (Standardized)')\n",
        "plt.ylabel('Feature 2 (Standardized)')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the clustering using silhouette score.\n",
        "silhouette_avg = silhouette_score(X_scaled, clusters)\n",
        "print('Silhouette Score: ',silhouette_avg)"
      ],
      "metadata": {
        "id": "0BOEV7WLgJCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge 2"
      ],
      "metadata": {
        "id": "Q9lFTfqSDEhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering challenge 2.\n",
        "# ---\n",
        "# This challenge is an extension of challange 1.\n",
        "# Using the same iris dataset, implement a hierarchical clustering model to assign\n",
        "# datapoints to clusters.\n",
        "# Evaluate the performance of your clustering model.\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW."
      ],
      "metadata": {
        "id": "quHGAmP-Iwp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution for challenge 2"
      ],
      "metadata": {
        "id": "Bazr0my5DHJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Create a dendrogram to determine the optimal number of clusters\n",
        "linked = linkage(X_scaled, 'ward')  # 'ward' method minimizes the variance within each cluster\n",
        "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
        "plt.title('Dendrogram for Hierarchical Clustering')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Cluster Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "voue6cxwK4ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply hierarchical clustering.\n",
        "optimal_k = 3\n",
        "hierarchical_model = AgglomerativeClustering(n_clusters=optimal_k)\n",
        "y_pred_hierarchical = hierarchical_model.fit_predict(X_scaled)\n",
        "\n",
        "# Visualize the clustering result.\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_pred_hierarchical)\n",
        "plt.title('Clustering Result (Wine Dataset)')\n",
        "plt.xlabel('Feature 1 (Standardized)')\n",
        "plt.ylabel('Feature 2 (Standardized)')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the clustering using silhouette score.\n",
        "silhouette_avg = silhouette_score(X_scaled, y_pred_hierarchical)\n",
        "print('Silhouette Score: ',silhouette_avg)"
      ],
      "metadata": {
        "id": "yDDcreKYgxyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}